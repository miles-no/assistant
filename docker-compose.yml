version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: miles-assistant-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: miles_booking
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5433:5432"  # Exposed for external tools (e.g., pgAdmin, DBeaver)
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - miles-network

  # API Backend
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: miles-assistant-api
    restart: unless-stopped
    environment:
      DATABASE_URL: "postgresql://postgres:postgres@postgres:5432/miles_booking?schema=public"
      PORT: 3000
      NODE_ENV: production
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-this}
    ports:
      - "3000:3000"  # Exposed for direct access if needed
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - miles-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Chat Application
  chat-app:
    build:
      context: ./chat-app
      dockerfile: Dockerfile
    container_name: miles-assistant-chat
    restart: unless-stopped
    environment:
      PORT: 3001
      NODE_ENV: production
      # Connect to host's Ollama (use host.docker.internal on Mac/Windows)
      OLLAMA_URL: ${OLLAMA_URL:-http://host.docker.internal:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2}
      # For Claude/OpenAI
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      # Connect to API service
      MCP_API_URL: http://api:3000/api/mcp
    ports:
      - "3001:3001"  # Exposed for direct access if needed
    depends_on:
      api:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - miles-network

  # IRIS Terminal Interface
  iris:
    build:
      context: ./iris
      dockerfile: Dockerfile
    container_name: miles-assistant-iris
    restart: unless-stopped
    environment:
      PORT: 3002
      NODE_ENV: production
      # Connect to API
      API_URL: http://api:3000
      MCP_API_URL: http://api:3000/api/mcp
      # LLM Provider configuration
      LLM_PROVIDER: ${LLM_PROVIDER:-ollama}
      OLLAMA_URL: ${OLLAMA_URL:-http://host.docker.internal:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-qwen2.5:7b}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      ANTHROPIC_MODEL: ${ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
    ports:
      - "3002:3002"  # Exposed for direct access if needed
    volumes:
      # Persist SQLite database for conversation history
      - iris_data:/app/data
    depends_on:
      api:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - miles-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3002/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # Web Frontend
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: miles-assistant-web
    restart: unless-stopped
    ports:
      - "3003:80"  # Exposed for direct access if needed
    depends_on:
      api:
        condition: service_healthy
    networks:
      - miles-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: miles-assistant-nginx
    restart: unless-stopped
    ports:
      - "80:80"  # Main entry point
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - web
      - api
      - chat-app
      - iris
    networks:
      - miles-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s

volumes:
  postgres_data:
    name: miles-assistant-postgres-data
  iris_data:
    name: miles-assistant-iris-data

networks:
  miles-network:
    name: miles-assistant-network
    driver: bridge
