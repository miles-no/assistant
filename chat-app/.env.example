# Server Configuration
PORT=3001

# LLM Provider Configuration
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama Configuration (when LLM_PROVIDER=ollama)
# Local LLM - no API key required
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b

# OpenAI Configuration (when LLM_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Anthropic Configuration (when LLM_PROVIDER=anthropic)
# Get your API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# MCP API Configuration
MCP_API_URL=http://localhost:3000/api/mcp
